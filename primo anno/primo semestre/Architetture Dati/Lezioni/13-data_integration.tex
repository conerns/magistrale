\section{Data Integration}
Si parla solitamente di:
\begin{itemize}
    \item \textbf{data integration}, dove si hanno diversi set di dati (anche non disgiunti) con attributi diversi. Si costruisce un unico insieme con tutti gli elementi dei due insiemi, con gli elementi presenti nell'eventuale intersezione con tutti gli attributi dei due insiemi di partenza . In pratica si fa un \textit{full outer join}. La tecnica di join considerata prende tutti i valori della tabella di sinistra e esegue un match, se possibile, con quelli della tabella di destra. In questo modo si prendono però poi anche tutti gli elementi che non sono collegati con una chiave esterna primaria (non fanno parte del join). Il risultato finale potrebbe non avere dell'informazione in più sui dati.
    \item \textbf{data enrichment}, dove voglio arricchire i dati di un insieme con quelli di altri insiemi, se possibile. In altre parole è una specie di \textit{left outer join}, devo si prendono tutti gli elementi della tabella di sinistra e vengono aggiunte le informazioni della tabella di destra. Questo nel caso in cui ci sia  un match, con i valori della tabella di sinistra, con la tabella di destra. In caso alternativo non aggiungo nulla. Si ha un match diverso dalla semplice uguaglianza tra il set che voglio arricchire e quello che contiene i potenziali arricchimenti. Potrei avere quindi uguaglianza, similitudine o altro, questo perché posso rilassare i vincoli di match quando voglio arricchire l'informazione. Il dataset arricchito contiene quindi solo gli elementi del dataset iniziale che volevo arricchire ma questi potrebbero (potrei non essere riuscito ad arricchire tutti i dati) contenere informazioni in più
\end{itemize}
In entrambi i casi per rappresentare l'assenza di un attributo uso un NULL nella tabella se si parla di un modello relazionale. In caso dei vari modelli NoSQL
seguo gli standard dei vari modelli e dei vari DBMS per rappresentare l'assenza di valore per un certo attributo.\\
Solitamente si cerca di aggiungere, per integrazione o arricchimento:
\begin{itemize}
    \item informazioni spaziali, con informazioni geografiche, o di appartenenza, dei dati che mancano e quindi vanno aggiunte
    \item informazioni temporali, con informazioni storiche dei dati da integrare/arricchire. Si ha però un problema di capire cosa venga prima e cosa dopo, per via della mancanza di timestamp, comportando ambiguità nel rapporto causa-effetto.
\end{itemize}
ma potrebbero esserci infinite altre casistiche.\\

\subsection{Eterogeneità}

Avere un livello di omogeneità facilita l'interazione tra diverse tabelle di un dataset, ma anche di architetture che usano una modalità di relazione diversa. Nel caso in cui siano eterogenei la situazione si complica ancora di più se ho modelli eterogenei, dal punto di vista dei modelli, avendo modelli sia relazionali che non relazioni.

Si hanno vari livelli di eterogeneità/conflitti:
\begin{itemize}
    \item \textbf{eterogeneità di nome}, legato a come sono state etichettate le eterogeneità. Ho quindi concetti di primo livello che rappresentano le stesse informazioni ma con label diverse.
    \item \textbf{eterogeneità di tipo}, ovvero a come modellizzo effettivamente un particolare pezzo della realtà
\end{itemize}
Oltre a questi si ha appunto l'\textbf{eterogeneità di modello} che copre ogni altro tipo di eterogeneo.
\subsubsection{Eterogeneità di nome}
Partiamo con questa prima categoria. Si hanno situazioni di:
\begin{itemize}
    \item \textbf{sinonimia}, ovvero rappresento lo stesso concetto con nomi diversi, che sono sinonimi. Sintassi diversa e semantica uguale.
    \item \textbf{omonimia}, ovvero rappresento concetti diversi con gli stessi nomi. Questo caso è più complicato da riconoscere (ad esempio potrei avere \textit{Città} in due schemi ma in uno rappresenta quella di nascita e in un altro quella di residenza) e rischia di comportare diversi errori, magari portando a dover decidere quale valore associare senza sapere come decidere, integrando in modo errato e perdendo informazione. Raramente si ha accesso alla documentazione dei dataset e quindi bisogna sperare che i vari attributi siano il meno ambigui possibile. Sintassi uguale e semantica diversa
    \item \textbf{iperonimia}, ovvero tra i due concetti uno è più di alto livello rispetto all'altra, secondo magari una relazione \textit{IS-A}.
\end{itemize}
\subsubsection{Eterogeneità di tipo}
In questo caso si ha che lo stesso concetto viene rappresentato in modo strutture concettualmente diverse in due schemi, potendo quindi avere, ad esempio:
\begin{itemize}
    \item domini di definizione differenti per lo stesso attributo in due schemi (ad esempio da una parte il dominio delle città italiane e dall'altro quelle  islandesi)
    \item un attributo in uno schema e avere un valore derivato in un altro schema, avendo quindi, nel primo caso, un attributo indipendente mentre nel secondo si ha una dipendenza funzionale con un altro attributo
    \item un attributo in uno schema e un entità in un altro schema 
    \item un attributo in uno schema e una gerarchia di generalizzazione in un altro schema 
    \item un'entità in uno schema e una relazione in un altro schema o magari, nel modello a grafo, avendo in uno schema un nodo e un arco nel secondo
    \item diversi livelli di astrazione per lo stesso concetto in due schemi (ad esempio due entità con nomi omonimi legati da una gerarchia IS-A in due schemi)  
    \item diverse granularità nei domini di definizione 
    \item diverse cardinalità nelle stesse relazioni 
    \item key conflicts (la chiave in uno schema è diverso da quella dell'altro)
\end{itemize}

\subsubsection{Data integration system}
Succede quindi che si ha una \textbf{trasformazione di schema}. Si procede con uno \textbf{schema matching} per capire come unificare i vari schemi per ottenere uno schema integrato omogeneo. Questo si fa capendo quali attributi coincidono anche se magari si presentano con sintassi diverse. \\
Il software che procede con queste fasi è detto \textbf{data integration system} che procede prendendo e mettendo insieme delle sorgenti dati e cerca di ottenere uno schema integrato. Vengono presi e uniti tutti gli attributi degli schemi.\\ \textit{In modo analogo funzionano i datawarehouse dove ho schemi diversi, solitamente relazionali ma non sempre, che vengono messi insieme e quindi manipolati}.\\

Ci sono diversi approcci che si possono utilizzare, infatti abbiamo una vera e propria classificazione delle varie tecniche, per eseguire il schema matching in modo da avere uno schema integrato immediato. Spesso bisogna fare schema matching \textit{on the fly} dovendo integrare nuovi schemi in modo assai rapido. Si hanno anche sistemi su grande scala con sistemi \textit{pay as you go}, dove serve altrettanta velocità.\\

Ci sono diverse fasi da eseguie:
\begin{enumerate}
    \item \textbf{schema transformation o pre-integration}, è una fase quindi propedeutica che presi in input $n$ schemi me li restituisce omogenei tramite tecniche di model trasformation o reverse engineering. 
    \item \textbf{Correspondences investigation}, dove si studiano le corrispondenze tra gli schemi tramite tecniche specifiche
    \item \textbf{schemas integration e mapping generation}, dove si definiscono lo schema integrato e le regole di mapping necessarie
\end{enumerate}
Per la fase di pre-integration, vediamo che  avendo da integrare/arricchire decine di schemi si hanno diverse strategie. Si hanno due scelte fondamentali:
\begin{enumerate}
    \item integro a coppie. Grazie a questa scelta binaria ho due possibilità:
        \begin{enumerate}
            \item prendere uno schema, integrarlo con un altro e integrare il risultato con un altro ancora etc$\ldots$. Ottengo una soluzione a scala con un albero binario non bilanciato
            \item uso un approccio bilanciato aggregando schemi vicini e aggregando poi i vari risultati delle integrazioni. Ottengo quindi un albero binario bilanciato 
        \end{enumerate}
    \item integro con più schemi contemporaneamente. Ho due approcci:
        \begin{enumerate}
            \item integrare tutti gli schemi insieme (\textbf{questo bisogna evitarlo} anche solo per $n>3$, si dovrebbero considerare tutte le permutazioni e non è facile)
            \item integrare in modo iterativo, in modo analogo a quanto fatto con il bilanciamento binario ma ovviamente non con un numero fisso di schemi da integrare ogni volta (magari ne integro due o magari tre, raramente di più per ovvi motivi)
        \end{enumerate}
\end{enumerate}

Invece per la seconda fase, quella di \textbf{Correspondences investigation}, si ha appunto anche il problema che posso dire le stesse cose con strutture completamente diverse. Si cercano quindi \textbf{corrispondenze semantiche} sfruttando la conoscenza pregressa sul dominio applicativo. Si possono sfruttare sia le \textbf{equivalenze}, ovvero componenti con gli stessi nomi (attenzione anche se hanno lo stesso nome possono rappresentare informazioni diverse), che le \textbf{generalità} (\textit{IS-A}) per cercare le eventuali corrispondenze. Si rischia di avere anche \textbf{disgiunzioni} tra attributi completamente diversi magari di schemi uguali rischiando di avere problemi.\\ 

Passiamo alla fase dinale, di \textbf{schemas integration e mapping generation}, ci serve capire come generare le regole di associazione. In uno schema non relazionale identificare i mapping è quindi molto arduo ma bisogna anche generare i nuovi mapping e le nuove regole di associazione.\\ Classificando i matching si trovano anche nuove tipologie di conflitto che devono essere risolti con trasformazioni opportune. Dobbiamo quindi meglio definire in primis i conflitti.
Si hanno diversi tipi di conflitti:
\begin{enumerate}
    \item \textbf{conflitti di classificazione} quando elementi omologhi descrivono insiemi diversi di oggetti del mondo reale. Si risolve tramite generalizzazione o specifica della gerarchia.
    \item \textbf{conflitti descrittivi} quando tipi omologhi hanno proprietà diverse o le stesse proprietà sono descritte diversamente. Si hanno:
        \begin{itemize}
            \item conflitti di nome, ovvero nomi diverse per le stesse cose
            \item conflitti di composizione, ovvero diversi attributi e/o metodi (magari avendone di più o di meno o anche diversi)
        \end{itemize}
    La soluzione dipende dai casi sulla base del tipo di conflitto incontrato e il tipo di classificazione del conflitto. 
    \item \textbf{conflitti strutturali} dove si hanno gli stessi elementi rappresentati tramite strutture diverse (magari da una parte un elemento è un'intera entità e dall'altra solo un attributo). Per risolvere si sceglie, per massimizzare l'informazione ottenuta, di prendere la struttura meno vincolata. Questo si fa per aumentare il volume delle informazioni.  
    \item \textbf{conflitti di frammentazione} dove magari lo stesso elemento è rappresentato da un singolo oggetto in uno schema mentre è rappresentato da diversi oggetti in un secondo database. Si integrano i dati quindi anche nell'ottica di rimetterli insieme.
\end{enumerate}

Parliamo quindi delle \textbf{regole di mapping} definite tra gli schemi di partenza e quelli ottenuti dopo l'integrazione. 
Si possono trovare, per lo schema di partenza $S$, osservando le trasformazioni effettuate per la risoluzione di omologie e conflitti avuti durante il processo di integrazione. Le regole mi dicono che un elemento chiamato in un modo nello schema integrato ha una precisa corrispondenza con un certo elemento di uno schema sorgente.\\
Se si hanno conflitti a livello direttamente di istanze, avendo che li stessi dati (lo stesso oggetto del mondo ideale) in sorgenti diversi hanno valori diversi, i problemi aumentano. Questo è un problema fondamentale nel data integration, anche nel caso dell'arricchimento. \\
Posso avere:
Date due sorgenti $S_1$ e $S_2$, siano $A_{1k}$ e $A_{1k}$ i valori che associati ad un attributo, rispettivamente, $t_1$ di $S_1$ e $t_2$ di $S_2$, abbiamo
\begin{itemize}
  \item un \textbf{conflitto di attributi} avendo due entità che rappresentano lo stesso oggetto reale con attributi diversi (anche solo uno) per la stessa proprietà. Le chiavi in questo caso sono coerenti. Occorre quindi se $A_{1k} \neq A_{1k}$
  \item un \textbf{conflitto di chiave} (detto anche \textbf{conflitto di entità \textnormal{o} conflitto di tupla}) se ho chiavi primarie diverse in due entità diverse che però rappresentano lo stesso oggetto mentre gli altri attributi coincidono
\end{itemize}
Una scelta di soluzione, detta \textbf{currency}, prevede, in caso di conflittualità di valore di attributo, di scegliere il valore inserito temporalmente per ultimo, nella speranza che sia il più aggiornato (ma spesso non è esattamente così). Le tecniche che trattano i conflitti a livello di istanza possono essere applicate in due diverse fasi del ciclo di vita di un sistema di integrazione dati, vale a dire:
\begin{itemize}
  \item a \textbf{design time}
  \item a \textbf{query time}
\end{itemize}
In entrambi i casi i conflitti saltano fuori a query time. Tuttavia, durante il design time si decide la strategia da seguire per risolvere i conflitti prima che le query vengano elaborate, ovvero nella fase di progettazione del sistema di integrazione dei dati. Le tecniche che operano a query time incorporano le specifiche della strategia da seguire all'interno della formulazione della query. 
Si hanno quindi le \textbf{funzioni di risoluzione dei conflitti} che prendono in input due valori conflittuali e hanno come output la risposta della query effettuata. Un criterio di misura si basa sull'affidabilità delle sorgenti stesse da cui proviene il conflitto. In altri casi si ragiona in termini di funzioni matematiche di minimo, massimo, media, varianza e altri concetti matematici, ma questo in presenza di valori numerici. Per valori non numerici si hanno altre funzioni, ad esempio la concatenazione nel caso di stringhe o la scelta delle più lunghe/corte. Ovviamente non si può sapere la risposta giusta ma si può imporre una logica di stima. È comunque buona pratica tenere traccia tali conflitti e in caso siano troppi preoccuparsi dell'effettiva validità dei dati. Il data integration assume due forme:
\begin{enumerate}
  \item \textbf{deduplicazione}, dove si scopre se ci sono concetti del mondo reale replicati nella tabella, avendo che l'integrazione viene fatta solo su quella tabella (non avendo schema matching), internamente. 
  \item integrazione in due tabelle diverse, avendo schema matching. Si supponga quindi di voler fondere due tabelle senza chiave primaria. Si cerca quindi una pseudo-chiave primaria (usando l'insieme più grande di attributi comuni alle tabelle che siano significativi, ad esempio nome, cognome e luogo di nascita) matchando le tabelle su di essa. Ma potrei anche qui non matchare per errori di scrittura. Faccio quindi un matching approssimato e concatenando le due tabelle e procedendo poi con la deduplica della tabella risultante. Potrei comunque sempre ragionare con la distanza di edit etc$\ldots$ restando con le tabelle separate, procedendo con una combinazione lineare degli score delle distanze (riscalate su $\{0,1\}$, con 1 match perfetto, facendo una somma pesata e dividendo per il numero di score), decidendo una soglia oltre la quale si ha il match. Si usano tecniche probabilistiche. 
\end{enumerate}

Si sono finora trascurati quei casi in cui si sta palesemente rappresentando la stessa cosa ma con termini diversi (magari con nomi contratti, esempio Leonardo che diventa Leo.). Si ha infatti il \textbf{record linkage}, ovvero la tecnica di risoluzione dei conflitti a livello di istanza, dove, date le tabelle in input, posso avere in output:
\begin{itemize}
  \item \textbf{matching tuples}, ovvero i valori che sicuramente matchano (anche se non perfetti ma con score oltre una certa soglia)
  \item \textbf{non matching tuples}, ovvero i valori che sicuramente non matchano
  \item \textbf{possible matches}, ovvero una sorta di area grigia dove non si sa come dare risposta. La scelta della soglia per il match e di quella per il non match, se scelta con valori dubbi, si avrà come conseguenza che molti casi siano dubbi, essendo quest'area quella compresa tra le due soglie.
\end{itemize}
In mezzo subentra l'umano che \textbf{a mano} sistema i valori, non avendo altro modo. Da qualche anno si è anche introdotto il machine learning, tramite \textbf{Deepr} per sostituire l'uomo nell'analisi di questa zona di mezzo. Le soluzioni di machine learning sono fortemente legate al dominio. \\

Si è dato per scontato un altro problema: le dimensione delle tabelle. In quel caso il check dei valori tra le tabelle esplode nel numero di confronti. Bisogna quindi ridurre lo \textbf{spazio di ricerca}, non potendo fare il prodotto cartesiano tra le tabelle ($ A\times B$), per via dei valori che ci si ritrovioamo a ricavare, quindi non è una soluzione che integra la \textbf{scalabilità}. \\
Vediamo quindi quali sono gli step che si incontrano eseguendo un \textbf{record linkage probabilistico}:
\begin{enumerate}
  \item \textbf{preprocessing}, normalizzazione dei formati (espansione abbreviazioni, lowercase, eliminazione spazi e caratteri speciali o passando ad altre codifiche, come la geocodifica) secondo uno standard
  \item \textbf{blocking}, riduzione dello spazio di ricerca. 
  \item \textbf{compare}, scegliendo una funzione di distanza e cercando un sample con coppie conosciute di match e unmatch. Per ogni caso calcolare il valore della distanza per frequenza di matching e unmatching.
  \item \textbf{decide}, valutando la distanza e le soglie
\end{enumerate}

Per la fusione posso:
\begin{itemize}
  \item ignorare un conflitto, mettendo tutti i valori disponibili
  \item cercare di evitare i conflitti basandomi sui metadati, sul sorgente o sulle istanze  
  \item gestire i conflitti tramite le funzioni di risoluzione dei conflitti e alle altre cose discusse sopra
\end{itemize}

Si hanno elenchi delle varie strategie possibili (ignorare, scegliere il più recente, scegliere il valore medio e molte altre), ognuna delle quali, come anche il record linkage, può introdurre errori. La scelta delle soglie inoltre può portare ad essere meno conservativi, introducendo falsi positivi, o troppo conservativi, riducendo drasticamente i match. Le varie scelte dipendono comunque dai singoli casi.